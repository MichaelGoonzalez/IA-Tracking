# Sistema de DetecciÃ³n y Tracking de Paquetes con YOLOv8

Este proyecto implementa un sistema de visiÃ³n por computadora avanzado para la detecciÃ³n y seguimiento (tracking) automÃ¡tico de paquetes en bandas transportadoras o entornos logÃ­sticos. Utiliza **YOLOv8** para una detecciÃ³n robusta y algoritmos de tracking como **ByteTrack** para mantener la identidad de los objetos a travÃ©s del tiempo.

## ğŸš€ CaracterÃ­sticas

-   **DetecciÃ³n en Tiempo Real**: Identifica paquetes con alta precisiÃ³n incluso en movimiento.
-   **Tracking Continuo**: Asigna IDs Ãºnicos a cada paquete para conteo y seguimiento.
-   **Entrenamiento Personalizado**: Scripts listos para entrenar el modelo con tus propios datos.
-   **Soporte GPU**: Optimizado para usar aceleraciÃ³n NVIDIA CUDA si estÃ¡ disponible.
-   **VisualizaciÃ³n en Vivo**: Muestra el video procesado con las cajas delimitadoras y trayectorias.

## ğŸ“‹ Requisitos Previos

-   Python 3.8, 3.9, 3.10 o 3.11 (Recomendado: 3.10).
-   Tarjeta grÃ¡fica NVIDIA (Opcional pero altamente recomendada para entrenamiento rÃ¡pido).
-   Drivers CUDA instalados (si se usa GPU).

## ğŸ› ï¸ InstalaciÃ³n

1.  **Clonar el repositorio:**
    ```bash
    git clone https://github.com/tu-usuario/IA-Tracking.git
    cd IA-Tracking
    ```

2.  **Crear un entorno virtual (Recomendado):**
    ```bash
    # En Windows
    python -m venv venv
    venv\Scripts\activate

    # En Linux/Mac
    python3 -m venv venv
    source venv/bin/activate
    ```

3.  **Instalar dependencias:**
    ```bash
    pip install -r requirements.txt
    ```
    *Nota: Si tienes una GPU NVIDIA, asegÃºrate de instalar la versiÃ³n de PyTorch compatible con CUDA (ej. `pip install torch torchvision --index-url https://download.pytorch.org/whl/cu118`).*

## ğŸ—‚ï¸ Estructura del Proyecto

```
IA-Tracking/
â”œâ”€â”€ config.yaml          # ConfiguraciÃ³n central (rutas, hiperparÃ¡metros, tracking)
â”œâ”€â”€ data/                # Dataset
â”‚   â”œâ”€â”€ images/          # ImÃ¡genes de entrenamiento y validaciÃ³n
â”‚   â”œâ”€â”€ labels/          # Etiquetas YOLO (.txt)
â”‚   â””â”€â”€ dataset.yaml     # DefiniciÃ³n de clases y rutas para YOLO
â”œâ”€â”€ models/              # Modelos entrenados (.pt)
â”œâ”€â”€ scripts/             # CÃ³digo fuente
â”‚   â”œâ”€â”€ detect.py        # Script principal de inferencia y tracking
â”‚   â”œâ”€â”€ train.py         # Script de entrenamiento
â”‚   â”œâ”€â”€ extract_frames.py # Herramienta para extraer imÃ¡genes de videos
â”‚   â””â”€â”€ split_dataset.py  # Herramienta para organizar datasets
â””â”€â”€ utils/               # Utilidades internas
```

## ğŸ® Uso

### 1. DetecciÃ³n y Tracking (Inferencia)
Para probar el modelo con un video existente (por defecto busca `prueba.mp4`):

```bash
python scripts/detect.py
```

Para usar otro video o una webcam:
```bash
# Video especÃ­fico
python scripts/detect.py --source ruta/a/tu/video.mp4

# Webcam en vivo
python scripts/detect.py --source 0
```
Se abrirÃ¡ una ventana mostrando el anÃ¡lisis en tiempo real. Los resultados se guardarÃ¡n en `runs/detect_track/`.

### 2. Entrenamiento de un Nuevo Modelo (Estable y Optimizado)
El sistema de entrenamiento es el nÃºcleo mÃ¡s robusto del proyecto. EstÃ¡ diseÃ±ado para ser "Plug & Play": detecta tu hardware (CPU/GPU), carga la configuraciÃ³n y optimiza los hiperparÃ¡metros automÃ¡ticamente.

#### Paso 1: Preparar tus Datos
1.  Coloca tus videos en la carpeta raÃ­z o extrae imÃ¡genes directamente.
2.  Usa `scripts/extract_frames.py` para convertir videos en imÃ¡genes si es necesario.
3.  Etiqueta tus imÃ¡genes (usando LabelImg, Roboflow, etc.) y guÃ¡rdalas en `data/raw_images` y `data/raw_labels`.

#### Paso 2: Organizar el Dataset
Ejecuta el script de organizaciÃ³n. Este script valida tus datos, ignora imÃ¡genes sin etiquetas y crea la estructura de carpetas que YOLO necesita automÃ¡ticamente:
```bash
python scripts/split_dataset.py --images data/raw_images --labels data/raw_labels
```

#### Paso 3: Iniciar Entrenamiento
Ejecuta el script maestro de entrenamiento:
```bash
python scripts/train.py
```
-   **DetecciÃ³n AutomÃ¡tica de GPU**: Si tienes una tarjeta NVIDIA, el script la usarÃ¡ automÃ¡ticamente para acelerar el proceso hasta 50x.
-   **Resultados**: Al finalizar, encontrarÃ¡s tu modelo listo para usar en `models/paquetes_tracking/weights/best.pt`.
-   **MÃ©tricas**: Se generan grÃ¡ficos de precisiÃ³n y pÃ©rdida en la misma carpeta para evaluar el rendimiento.

## âš™ï¸ ConfiguraciÃ³n Avanzada
El archivo `config.yaml` permite ajustar:
-   **HiperparÃ¡metros**: `epochs`, `batch_size`, `imgsz`.
-   **Aumentos de Datos**: `degrees` (rotaciÃ³n), `scale`, `flip`, etc., para hacer el modelo mÃ¡s robusto.
-   **Tracking**: Tipo de tracker (`bytetrack.yaml` o `botsort.yaml`) y umbrales de confianza.

## ğŸ“„ Licencia
Este proyecto es de cÃ³digo abierto y estÃ¡ disponible para uso educativo y comercial.
